<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Chapter 07" />
  <title>Spark the Definitive Guide 2nd Edition</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Spark the Definitive Guide 2nd Edition</h1>
  <p class="author">
Chapter 07
  </p>
  <p class="date">Aggregations</p>
</div>
<div id="aggregations" class="title-slide slide section level1"><h1>Aggregations</h1></div><div id="text-book" class="slide section level2">
<h1>Text Book</h1>
<div class="figure">
<img src="images/spark-book.png" title="Spark TextBook" alt="itmd-521 textbook" />
<p class="caption"><em>itmd-521 textbook</em></p>
</div>
</div><div id="objectives-and-outcomes" class="slide section level2">
<h1>Objectives and Outcomes</h1>
<ul class="incremental">
<li>Aggregating is the act of collecting something together
<ul class="incremental">
<li>It is the cornerstone of big data analytics</li>
</ul></li>
<li>You specify a <em>key</em> or <em>grouping</em> and an <em>aggregation function</em>
<ul class="incremental">
<li>This function specifies how you should transform one or more columns</li>
</ul></li>
<li>Spark allows us to create the following types of groupings:
<ul class="incremental">
<li>A <em>“group by”</em> specifies one or more keys and one or more aggregations</li>
<li>A <em>“window”</em> specifies one or more keys and one or more aggregations to transform the value columns</li>
<li>A <em>“grouping set”</em> specifies you can use aggregations at multiple levels</li>
<li>A <em>“rollup”</em> specifies one or more keys as well as one or more aggregation functions to transform the value of a column</li>
<li>A <em>“cube”</em> specifies one or more keys as well as one or more aggregations to transform the value columns</li>
</ul></li>
</ul>
</div><div id="review" class="slide section level2">
<h1>Review</h1>
<ul class="incremental">
<li>So far:
<ul class="incremental">
<li>We learned how to build expressions using typed data</li>
<li>We learned how to use:</li>
<li>Booleans</li>
<li>Numbers</li>
<li>Strings</li>
<li>Dates and Timestamps</li>
<li>Nulls</li>
<li>Complex and user types</li>
</ul></li>
</ul>
</div><div id="basic-aggregations" class="slide section level2">
<h1>Basic Aggregations</h1>
<ul class="incremental">
<li>One of the simplest aggregations is <code>count()</code> which will count all rows in a DataFrame
<ul class="incremental">
<li><code class="sourceCode python">df.count()</code></li>
<li><code>.count()</code> is technically an action not a transformation</li>
</ul></li>
<li>Elements of an entire column can be counted as well
<ul class="incremental">
<li><code class="sourceCode python"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> count</code></li>
<li><code class="sourceCode python">df.select(count(<span class="st">&quot;StockCode&quot;</span>)).show()</code></li>
<li>Watch out! When counting all columns ("*") Spark will count <code>nulls</code>, even rows that are all <code>null</code></li>
<li>When counting an individual column, Spark will not count <code>nulls</code></li>
</ul></li>
</ul>
</div><div id="countdistinct" class="slide section level2">
<h1>countDistinct</h1>
<ul class="incremental">
<li>Sometimes total number is not relevant, only unique number is
<ul class="incremental">
<li>There is a <code>.countDistinct()</code> function</li>
<li><code class="sourceCode python"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> countDistinct</code></li>
<li><code class="sourceCode python">df.select(countDistinct(<span class="st">&quot;StockCode&quot;</span>)).show()</code></li>
</ul></li>
<li>There is also an <code class="sourceCode python">.approx_count_distinct()</code>
<ul class="incremental">
<li>When working with a large dataset, time, processing power, even energy usage are a consideration</li>
<li>There are times when a degree of approximation can be used without an issue</li>
<li><code class="sourceCode python"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> approx_count_distinct</code></li>
<li><code class="sourceCode python">df.select(approx_count_distinct(<span class="st">&quot;StockCode&quot;</span>, <span class="fl">0.1</span>)).show()</code></li>
<li><code class="sourceCode sql"><span class="kw">SELECT</span> approx_count_distinct(StockCode, <span class="fl">0.1</span>) <span class="kw">FROM</span> dfTable</code></li>
<li>0.1 is the estimation error margin</li>
<li>Note the results, but note the performance gain</li>
</ul></li>
</ul>
</div><div id="simple-aggregations" class="slide section level2">
<h1>Simple Aggregations</h1>
<ul class="incremental">
<li>You can get the first and last elements of a DataFrame by two obvious elements
<ul class="incremental">
<li>.first()</li>
<li>.last()</li>
</ul></li>
<li>You can extract min and max values using the builtin pyspark sql functions</li>
<li>You can use the <code>sum</code> method to sum the content of a column
<ul class="incremental">
<li>There is also a <code>sumDistinct</code> function that will perform that actions as well</li>
</ul></li>
<li>There is an <code>avg</code> function to do an average of a column
<ul class="incremental">
<li>You can combine this result with an alias to reuse the calculated value later 107</li>
</ul></li>
<li>If you are calculating Average, then you are dealing with <em>Variance</em> and <em>Standard Deviation</em></li>
<li><em>Skewness</em> and <em>kurtosis</em> are both measurements of extreme points in your data
<ul class="incremental">
<li>Skewness measures the asymmetry of your values around the mean</li>
<li>Kurtosis measures the tail of data</li>
</ul></li>
</ul>
</div><div id="more-simple-aggregations" class="slide section level2">
<h1>More Simple Aggregations</h1>
<ul class="incremental">
<li>Some functions compare the interactions of the values in two different columns together
<ul class="incremental">
<li><em>Covariance</em> and <em>Correlation</em></li>
<li><code>cov</code> and <code>corr</code></li>
<li>Chapter 6 talked about the <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" title="Pearson Correlation coefficient wiki page">Pearson correlation coefficient</a></li>
<li>Correlation is measured on a -1 to 1 scale</li>
<li>The covariance can be taken over a population sample or the entire population of records 110</li>
</ul></li>
</ul>
</div><div id="grouping" class="slide section level2">
<h1>Grouping</h1>
<ul class="incremental">
<li>We have done <code class="sourceCode python">groupBy</code> on the DataFrame level aggregations
<ul class="incremental">
<li>We can perform calculations based on <em>groups</em> in the data</li>
<li>Using our purchase data DataFrame, for example we can group on unique <strong>invoice number</strong> and do a <code>count()</code> of items on that invoice</li>
<li>This returns a second DataFrame that is lazily evaluated</li>
<li><code class="sourceCode python">df.groupBy(<span class="st">&quot;InvoiceNo&quot;</span>,<span class="st">&quot;CustomerId&quot;</span>).count().show()</code></li>
<li><code class="sourceCode sql"><span class="kw">SELECT</span> <span class="fu">count</span>(<span class="op">*</span>) <span class="kw">FROM</span> dfTable <span class="kw">GROUP</span> <span class="kw">BY</span> InvoiceNo, CustomerId</code></li>
</ul></li>
<li>We can specify an arbitrary expression statement as an <code>agg</code> statement
<ul class="incremental">
<li>This makes it possible to say <em>alias</em> a column</li>
<li><code class="sourceCode python">df.groupBy(<span class="st">&quot;InvoiceNo&quot;</span>).agg(count(<span class="st">&quot;Quantity&quot;</span>).alias(<span class="st">&quot;quan&quot;</span>), expr(count(Quantity)<span class="st">&quot;)).show()</span></code></li>
</ul></li>
</ul>
</div><div id="grouping-with-maps" class="slide section level2">
<h1>Grouping With Maps</h1>
<ul class="incremental">
<li>Sometimes it can be easier to specify your transformations as a series of <strong>Maps</strong>
<ul class="incremental">
<li>For which the key is the column</li>
<li>The value is the aggregation function that you would like to perform</li>
</ul></li>
<li><code class="sourceCode python">df.groupBy(<span class="st">&quot;InvoiceNo&quot;</span>).agg(expr(<span class="st">&quot;avg(Quantity)&quot;</span>),expr(<span class="st">&quot;stddev_pop(Quantity)&quot;</span>)).show()</code></li>
</ul>
</div><div id="window-functions-112" class="slide section level2">
<h1>Window Functions 112</h1>
<ul class="incremental">
<li>Window Functions can be used to carry out aggregations by computing on a certain <em>window</em> of data
<ul class="incremental">
<li>This sounds very similar to a <code class="sourceCode python">groupBy</code> function, so what is the difference?</li>
<li><code class="sourceCode python">groupBy</code> takes data and every row can only go into one grouping</li>
<li>A Window function calculates a return value for every input row of a table based on groups of rows, called a <strong>frame</strong>
<ul class="incremental">
<li>Not a DataFrame</li>
</ul></li>
<li>Each row can fall into one or more frame, unlike a <code class="sourceCode python">groupBy</code></li>
<li><img src="images/figure-7-1.png" title="fig:Image Visualizing a Window Function" alt="Figure 7.1 Visualizing a Window" /></li>
</ul></li>
</ul>
</div><div id="example-of-a-window" class="slide section level2">
<h1>Example of a Window</h1>
<ul class="incremental">
<li>First we need to create a Window Specification</li>
<li><code class="sourceCode python">windowSpec <span class="op">=</span> Window.partitionBy(<span class="st">&quot;CustomerId&quot;</span>,<span class="st">&quot;date&quot;</span>).orderBy(desc(<span class="st">&quot;Quantity&quot;</span>)).rowsBetween(Window.unboundedPreceeding,Window.currentRow)</code>
<ul class="incremental">
<li>First the <em>partitionBy</em> here has nothing to do with storage partitions</li>
<li><code>orderBy</code> is how the Window will be sorted</li>
<li><code>rowsBetween</code> is the range of the Window</li>
</ul></li>
<li>We can now run aggregation functions over these Windows
<ul class="incremental">
<li><code class="sourceCode python">maxPurchaseQuantity <span class="op">=</span> <span class="bu">max</span>(col(<span class="st">&quot;Quantity&quot;</span>).over(<span class="st">&quot;WindowSpec&quot;</span>))</code></li>
<li>This statement returns a column, which can be used in a DataFrame Select statement for further analysis</li>
<li>We could now establish the maximum purchase quantity for each customer over all time</li>
<li><code>dense_rank()</code> and <code>rank()</code></li>
</ul></li>
</ul>
</div><div id="remaining-aggregations" class="slide section level2">
<h1>Remaining Aggregations</h1>
<ul class="incremental">
<li>Lets take a look at the end of the chapter for definitions as the code sample helps immensely in defining these
<ul class="incremental">
<li>Rollups</li>
<li>GroupingSets</li>
<li>Cubes</li>
<li>Pivot</li>
</ul></li>
</ul>
</div><div id="conclusion" class="slide section level2">
<h1>Conclusion</h1>
<ul class="incremental">
<li>We walked through the types of aggregations, from simply groupBy to Window Functions. These are the basic sets of aggregations that can be performed.</li>
</ul>
</div><div id="questions" class="slide section level2">
<h1>Questions</h1>
<ul class="incremental">
<li>Any questions?</li>
<li>Read Chapter 08 &amp; 09 and do any exercises in the book.</li>
</ul>
</div>
</body>
</html>
